# Link to Collab Notebook: https://colab.research.google.com/drive/1UWK0bokfmchgTqfJ8TCHS7T3_fIi35SO?usp=sharing

import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import ast # Used for safely evaluating string representations of dicts if needed

# --- Configuration ---
# Specify the path to the final processed CSV file (output of evaluate_prompts.py)
PROCESSED_FILE_PATH = 'prompt_dataset/textdescriptives_processed_prompt_examples_dataset.csv'
TARGET_COLUMN = 'prompt_qual'
TEST_SIZE = 0.2 # Proportion of data to use for testing
RANDOM_STATE = 42 # For reproducibility

# --- Load Data ---
print(f"Loading data from: {PROCESSED_FILE_PATH}")
try:
    df = pd.read_csv(PROCESSED_FILE_PATH)
    print("Data loaded successfully.")
    print("Initial DataFrame info:")
    df.info()
    print("\nFirst 5 rows:")
    print(df.head())
except FileNotFoundError:
    print(f"Error: File not found at {PROCESSED_FILE_PATH}")
    print("Please ensure 'extract_data.py' and 'evaluate_prompts.py' have been run successfully.")
    exit()
except Exception as e:
    print(f"An error occurred while loading the data: {e}")
    exit()

# --- Feature Engineering & Selection ---
print("\nStarting feature engineering...")

# Define potential feature columns generated by textdescriptives
# Note: Some of these might be dictionaries stored as strings or actual dict objects.
potential_feature_cols = [
    "readability", "token_length", "sentence_length",
    "coherence", "information_theory", "entropy",
    "perplexity", "per_word_perplexity"
]

# Identify columns that actually exist in the DataFrame
existing_feature_cols = [col for col in potential_feature_cols if col in df.columns]
print(f"Found potential feature columns: {existing_feature_cols}")

# Flatten dictionary-like columns
features_list = []
for col in existing_feature_cols:
    # Check if the column contains string representations of dictionaries
    if isinstance(df[col].iloc[0], str) and df[col].iloc[0].startswith('{'):
        try:
            # Safely evaluate the string to a dictionary
            expanded_col = df[col].apply(ast.literal_eval)
            # Normalize the dictionary into separate columns
            normalized_df = pd.json_normalize(expanded_col)
            # Add prefix to avoid name collisions
            normalized_df.columns = [f"{col}_{sub_col}" for sub_col in normalized_df.columns]
            features_list.append(normalized_df)
            print(f"Flattened string-dict column: {col}")
        except (ValueError, SyntaxError) as e:
            print(f"Warning: Could not parse column '{col}' as dictionary: {e}. Skipping.")
        except Exception as e:
             print(f"Warning: An unexpected error occurred processing column '{col}': {e}. Skipping.")

    # Check if the column contains actual dictionary objects
    elif isinstance(df[col].iloc[0], dict):
         try:
            # Normalize the dictionary into separate columns
            normalized_df = pd.json_normalize(df[col])
             # Add prefix to avoid name collisions
            normalized_df.columns = [f"{col}_{sub_col}" for sub_col in normalized_df.columns]
            features_list.append(normalized_df)
            print(f"Flattened dict column: {col}")
         except Exception as e:
             print(f"Warning: An unexpected error occurred processing dict column '{col}': {e}. Skipping.")

    # Assume it's a simple numeric column if not a dict/string-dict
    elif pd.api.types.is_numeric_dtype(df[col]):
        features_list.append(df[[col]]) # Keep as is
        print(f"Using numeric column directly: {col}")
    else:
        print(f"Warning: Column '{col}' is not numeric or a recognized dictionary format. Skipping.")


# Combine all processed features
if not features_list:
    print("Error: No valid features found after processing. Exiting.")
    exit()

X = pd.concat(features_list, axis=1)

# --- Handle Missing Values (Example: Impute with mean) ---
# Check for NaNs introduced during processing
if X.isnull().sum().sum() > 0:
    print("\nWarning: Missing values found in features. Imputing with mean.")
    print(X.isnull().sum())
    for col in X.columns:
        if X[col].isnull().any():
            mean_val = X[col].mean()
            X[col].fillna(mean_val, inplace=True)
            print(f"Imputed column: {col} with mean {mean_val:.4f}")
else:
    print("\nNo missing values found in features.")


print("\nFinal features prepared:")
X.info()
print(X.head())

# --- Target Variable Preparation ---
print(f"\nPreparing target variable: {TARGET_COLUMN}")
if TARGET_COLUMN not in df.columns:
    print(f"Error: Target column '{TARGET_COLUMN}' not found in the DataFrame.")
    exit()

y = df[TARGET_COLUMN]

# Encode target labels ('bad' -> 0, 'good' -> 1)
le = LabelEncoder()
y_encoded = le.fit_transform(y)
print(f"Target variable encoded: {list(le.classes_)} -> {list(range(len(le.classes_)))}")
print(f"Value counts:\n{pd.Series(y_encoded).value_counts()}")


# --- Data Splitting ---
print(f"\nSplitting data into training and testing sets (Test size: {TEST_SIZE}, Random State: {RANDOM_STATE})...")
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded,
    test_size=TEST_SIZE,
    random_state=RANDOM_STATE,
    stratify=y_encoded # Ensure proportional representation of classes
)
print(f"Training set shape: X={X_train.shape}, y={y_train.shape}")
print(f"Testing set shape: X={X_test.shape}, y={y_test.shape}")

# --- Model Training ---
print("\nTraining XGBoost Classifier...")
# Initialize XGBoost classifier
# Common parameters:
# n_estimators: Number of boosting rounds (trees)
# learning_rate: Step size shrinkage to prevent overfitting
# max_depth: Maximum depth of a tree
# objective: 'binary:logistic' for binary classification
# eval_metric: Metric used for evaluation on validation sets (e.g., 'logloss', 'error')
# use_label_encoder=False is recommended for newer XGBoost versions
xgb_clf = xgb.XGBClassifier(
    objective='binary:logistic',
    eval_metric='logloss',
    use_label_encoder=False, # Set to False for newer XGBoost versions
    n_estimators=100,
    learning_rate=0.1,
    max_depth=3,
    random_state=RANDOM_STATE
)

# Train the model
xgb_clf.fit(X_train, y_train)
print("Model training complete.")

# --- Model Evaluation ---
print("\nEvaluating model on the test set...")
y_pred = xgb_clf.predict(X_test)
y_pred_proba = xgb_clf.predict_proba(X_test)[:, 1] # Probabilities for the positive class

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"\nAccuracy: {accuracy:.4f}")

# Print classification report
print("\nClassification Report:")
# Use target_names to show 'bad' and 'good' instead of 0 and 1
print(classification_report(y_test, y_pred, target_names=le.classes_))

# Print confusion matrix
print("\nConfusion Matrix:")
cm = confusion_matrix(y_test, y_pred)
print(pd.DataFrame(cm, index=le.classes_, columns=[f"Predicted {c}" for c in le.classes_]))

# --- Feature Importance (Optional) ---
try:
    print("\nFeature Importances:")
    importances = pd.DataFrame({
        'Feature': X.columns,
        'Importance': xgb_clf.feature_importances_
    }).sort_values(by='Importance', ascending=False)
    print(importances)
except Exception as e:
    print(f"Could not display feature importances: {e}")


print("\n--- Pipeline Finished ---")
